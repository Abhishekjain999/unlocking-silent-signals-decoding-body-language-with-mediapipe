Unlocking Silent Signals: Decoding Body Language with MediaPipe
This project is a real-time body language decoder powered by MediaPipe, OpenCV, and scikit-learn. It analyzes human facial expressions, hand gestures, and full-body posture to interpret emotional and behavioral cues from live video input.

ðŸ§  Features

Real-time emotion prediction using webcam input

Facial landmark detection (eyes, eyebrows, lips, jawline)

Hand tracking and gesture recognition

Body pose estimation using MediaPipe Holistic

Machine learning pipeline for classification of body language

Customizable UI and easy integration for researchers, educators, and developers

ðŸ§° Tech Stack

MediaPipe Holistic

OpenCV

scikit-learn (for training + prediction)

NumPy, Pandas

Flask (for deployment, optional)

ðŸ“¦ Use Cases

Virtual interview analysis

Non-verbal communication training

Behavioral research

Interactive AI-based educational tools

